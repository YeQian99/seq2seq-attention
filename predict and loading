## 模型的预测和加载
#模型加载
model.load_state_dict(torch.load('./temp/model.pt'))
 
 
#构建预测函数，输入生成摘要的字符串
""""
构建生成的函数，输入原文的字符串，输出生成摘要的字符串，参数为：
doc_sentence：摘要的字符串
doc_field：之前定义的针对document的预处理格式DOCUMENT
sum_field：之前定义的针对summary的预处理格式SUMMARY
model：训练的seq2seq模型
device：数据存放的设备
max_len：生成摘要的最长长度
"""
 
def generate_summary(doc_sentence,doc_field,sum_field,model,device,max_len=50):
    # 将模型置为验证模式
    model.eval()
 
    # 对原文分词
    nlp = spacy.load('en_core_web_md')
    #     nlp = spacy.load('en_core_web_md')
    tokens = [token.text.lower() for token in nlp(doc_sentence)]
 
    # 为原文加上起始符号<sos>和结束符号<eos>
    tokens = [doc_field.init_token] + tokens + [doc_field.eos_token]
 
    # 将字符转换成序号
    doc_indexes = [doc_field.vocab.stoi[token] for token in tokens]
 
    # 转换成可以gpu计算的tensor
    doc_tensor = torch.LongTensor(doc_indexes).unsqueeze(1).to(device)
 
    doc_len = torch.LongTensor([len(doc_indexes)]).to(device)
 
    # 计算encoder
    with torch.no_grad():
        encoder_outputs, hidden = model.encoder(doc_tensor, doc_len)
 
    mask = model.create_mask(doc_tensor)
    # 生成摘要的一个单词 <sos>
    sum_indexes = [sum_field.vocab.stoi[sum_field.init_token]]
 
    # 构建一个attention tensor，存储每一步的attention
    attentions = torch.zeros(max_len, 1, len(doc_indexes)).to(device)
 
    for i in range(max_len):
 
        sum_tensor = torch.LongTensor([sum_indexes[-1]]).to(device)
 
        # 计算每一步的decoder
        with torch.no_grad():
            output, hidden, attention = model.decoder(sum_tensor, hidden, encoder_outputs, mask)
 
        attentions[i] = attention
 
        pred_token = output.argmax(1).item()
 
        # 如果出现了 <eos> 则直接结束计算
        if pred_token == sum_field.vocab.stoi[sum_field.eos_token]:
            break
 
        sum_indexes.append(pred_token)
 
    # 把序号转换成单词
    sum_tokens = [sum_field.vocab.itos[i] for i in sum_indexes]
 
    return sum_tokens[1:], attentions[:len(sum_tokens)-1]
 
#读取数据
data_test = pd.read_csv("datasets/test.csv",encoding='utf-8')
data_test = data_test[:100]
doc_sentence_list = data_test['document'].tolist()
sum_sentence_list = data_test['summary'].tolist()
 
#开始进行预测
generated_summary = []
 
for doc_sentence in doc_sentence_list:
    summary_words,attention = generate_summary(doc_sentence,DOCUMENT,SUMMARY,model,device,max_len = 50)
    summary_sentence = (' ').join(summary_words)
 
    generated_summary.append(summary_sentence)
 
# 输出一个生成的摘要
 
indices = random.sample(range(0, len(sum_sentence_list)), 5)
 
for index in indices:
    print("document:")
    print(doc_sentence_list[index])
 
    print("generated summary:")
    print(generated_summary[index])
 
    print("reference summary:")
    print(sum_sentence_list[index])
 
    print("---------------")
 
#模型加载
model.load_state_dict(torch.load('./temp/model.pt'))
# 输出测试集损失
test_loss = evaluate(model, test_iter, criterion)
 
print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')
 
#输出评估指标
from rouge import Rouge
 
rouge = Rouge()
#scores = rouge.get_scores(generated_summary, sum_sentence_list,avg=True)
scores = rouge.get_scores(generated_summary,sum_sentence_list,avg=True)
print(scores)
